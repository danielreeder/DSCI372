{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3c89c3f7-cdee-4dfd-a87a-737d1f4d1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "51c3ff80-3d99-4036-8f4b-b48ddda5648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/covtype.data.gz\", names=np.array([\"elevation\", \"aspect\", \"slope\", \"horizontal_distance_to_hydrology\", \"vertical_distance_to_hydrology\", \"horizontal_distance_to_roadways\", \"hillshade_9am\", \"hillshade_noon\", \"hillshade_3pm\", \"horizontal_distance_to_fire_points\", \"wilderness_area_1\", \"wilderness_area_2\", \"wilderness_area_3\", \"wilderness_area_4\", \"soil_type_1\", \"soil_type_2\", \"soil_type_3\", \"soil_type_4\", \"soil_type_5\", \"soil_type_6\", \"soil_type_7\", \"soil_type_8\", \"soil_type_9\", \"soil_type_10\", \"soil_type_11\", \"soil_type_12\", \"soil_type_13\", \"soil_type_14\", \"soil_type_15\", \"soil_type_16\", \"soil_type_17\", \"soil_type_18\", \"soil_type_19\", \"soil_type_20\", \"soil_type_21\", \"soil_type_22\", \"soil_type_23\", \"soil_type_24\", \"soil_type_25\", \"soil_type_26\", \"soil_type_27\", \"soil_type_28\", \"soil_type_29\", \"soil_type_30\", \"soil_type_31\", \"soil_type_32\", \"soil_type_33\", \"soil_type_34\", \"soil_type_35\", \"soil_type_36\", \"soil_type_37\", \"soil_type_38\", \"soil_type_39\", \"soil_type_40\", \"cover type\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5ec164e7-e89a-436d-a015-580a53e41870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    # take a sample of 15,000 observations from the original data set\n",
    "    # done to speed up computation times, original dataset contains >500,000 samples\n",
    "    df = df.sample(15000)\n",
    "\n",
    "    # ensure that the dataset has no null values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # standardize numerical data\n",
    "    standard_scaler = StandardScaler()\n",
    "    df.loc[:, \"elevation\":\"horizontal_distance_to_fire_points\"] = standard_scaler.fit_transform(df.loc[:, \"elevation\":\"horizontal_distance_to_fire_points\"])\n",
    "\n",
    "    # split original dataset into train and test set, 80/20 ratio\n",
    "    train, test = train_test_split(df, test_size=0.2, train_size=0.8)\n",
    "\n",
    "    # split train set into a final train set and a validation set, 80/20 ratio\n",
    "    train, valid = train_test_split(train, test_size=0.2, train_size=0.8)\n",
    "    train.reset_index(drop=True, inplace=True); valid.reset_index(drop=True, inplace=True); test.reset_index(drop=True, inplace=True);\n",
    "\n",
    "    # separate features from labels for train, valid, and test sets\n",
    "    X_train = train.iloc[:, :-1]; y_train = train.iloc[:, -1];\n",
    "    X_valid = valid.iloc[:, :-1]; y_valid = valid.iloc[:, -1];\n",
    "    X_test = test.iloc[:, :-1]; y_test = test.iloc[:, -1];\n",
    "\n",
    "    X_train.to_csv('data/X_train.csv')\n",
    "    X_valid.to_csv('data/X_valid.csv')\n",
    "    X_test.to_csv('data/X_test.csv')\n",
    "    y_train.to_csv('data/y_train.csv')\n",
    "    y_valid.to_csv('data/y_valid.csv')\n",
    "    y_test.to_csv('data/y_test.csv')\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b09acff2-ebb6-4083-a4e6-ffd896a2246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24601fd5-213d-4946-a285-193798f44146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce85da-b5ed-4287-8f13-893208722e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
