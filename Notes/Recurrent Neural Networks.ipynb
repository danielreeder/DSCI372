{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26815dca-40f4-4107-8ab9-308750e76851",
   "metadata": {},
   "source": [
    "# Vanilla Neural Network:\n",
    "    1 to 1\n",
    "    not a good choice for processing a sequence of data\n",
    "    |--| --> |--| --> |--|\n",
    "\n",
    "    1 to many\n",
    "    ex. image captioning: image --> sequence of words\n",
    "\n",
    "    many to 1\n",
    "    ex. action prediction: sequence of video frames --> action class\n",
    "\n",
    "    many to many\n",
    "    ex. video captioning: sequence of video frames --> sequence of words\n",
    "\n",
    "# Recurrent Neural Network\n",
    "    key idea: RNNs have an internal state that is updated as a sequence is processed\n",
    "    multiple copies of the same neural network\n",
    "\n",
    "    Unrolled RNN:\n",
    "    \n",
    "        [y1]       [y2]\n",
    "         ^    h1    ^    h2\n",
    "    h0  [A]   -->  [A]   --> etc.\n",
    "         ^          ^\n",
    "        [x1]       [x2]\n",
    "\n",
    "    RNN Hidden State Update:\n",
    "        we can process a sequence of vectors x by applying a recurrence formula at every time step:\n",
    "            ht = fw(ht-1, xt)\n",
    "            ht = new state\n",
    "            fw = some function w/ parameters W\n",
    "            ht-1 = old state\n",
    "            xt = input vector at time step t\n",
    "            \n",
    "        RNN Output Generation:\n",
    "            yt = fWhy(ht)\n",
    "            yt = output\n",
    "            fWhy = another function with parameters Why\n",
    "            ht = new state\n",
    "\n",
    "        Note: the same function and the same set of parameters are used at every time step\n",
    "\n",
    "        ht = fw(ht-1, xt)\n",
    "\n",
    "        common simple RNN:\n",
    "            fw = tanh(), ht = tanh(Whh * ht-1 + Wxh * xt)\n",
    "\n",
    "        re-use same weight matrix at every time-step\n",
    "        \n",
    "    Long Short Term Memory (LSTM)\n",
    "        a type of RNN\n",
    "\n",
    "\n",
    "    torch.nn.LSTMCell(input_size, hidden_size, bias=True, device=None, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "252beb23-c207-4196-90fd-3bd857f05477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66022e60-d164-4e7b-b72c-978a45e3b822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.detach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf0a39-fcfd-4613-923c-414f03dea1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
