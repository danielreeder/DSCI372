{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27eff97a-13bc-4c3a-936f-bdc44dc59456",
   "metadata": {},
   "source": [
    "#### K-Means\n",
    "    dataset = {x1, x2, x3, ..., xn}\n",
    "    initialize K random points as cluster centers {uk}\n",
    "\n",
    "    repeat:\n",
    "        assign data points xi to closest cluster center\n",
    "            arg mink d(xi, uk)\n",
    "        update the cluster center to the average of its assigned points\n",
    "            uk = sum(xi for i in k) / numpoints(k)\n",
    "    until no point assignments change\n",
    "\n",
    "    properties:\n",
    "        guaranteed to converge in a finite number of iterations\n",
    "        runtime per iteration: N data points, K clusters\n",
    "            assign data points to closest center O(KN) time\n",
    "            updata cluster center to average of its assigned points O(N) time\n",
    "        performance depends on:\n",
    "            number of clusters: K (hyperparameter)\n",
    "            initial cluster center\n",
    "        can get \"stuck\" in local optimum\n",
    "\n",
    "    Hierarchical clustering\n",
    "        K-means\n",
    "            requires pre-specification of number of clusters K\n",
    "            depends on random init\n",
    "\n",
    "        Hierarchical clustering\n",
    "            does not require a pre-specified schoice of K\n",
    "            deterministic\n",
    "            \n",
    "        Algorithms\n",
    "            bottom up - agglomerative\n",
    "            top down - divisive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93726369-d1e8-4f05-9fa6-cab2a2416827",
   "metadata": {},
   "source": [
    "#### Agglomerative Clustering\n",
    "    dataset: {x1, x2, ..., xn}\n",
    "    initialize each instance in its own cluster\n",
    "    repeat:\n",
    "        pick the two closest clusters and merge them\n",
    "    until only one cluster left\n",
    "    key: how do we measure dissimilarity/distance between clusters?\n",
    "\n",
    "    Linkages:\n",
    "        dissimilarity between two clusters\n",
    "        given two cluster G and H, a linkage is a dissimilarity measure d(G, H)\n",
    "            tells us how different the points are\n",
    "        common types\n",
    "            complete\n",
    "            single\n",
    "            average\n",
    "            centroid\n",
    "\n",
    "    Single Linkage:\n",
    "        dissimilarity between G and H is the smallest dissimilarity between two points in different groups\n",
    "        suffers from chaining\n",
    "            in order to merge two clusters, only need one pair of points to be close\n",
    "            clusters can be spread out, not compact\n",
    "\n",
    "    Complete Linkage:\n",
    "        dissimilarity between G and H is the LARGEST distance between two points in different groups\n",
    "        opposite of single linkage\n",
    "        avoids chaining, but suffers from crowding\n",
    "        a point can end up being closer to points in other clusters than to points in its own\n",
    "\n",
    "    Average Linkage:\n",
    "        dissimilarity between two clusters G, H is the average dissimilarity over all points in different groups\n",
    "        tries to strike a balance\n",
    "        clusters tend to be relatively compact and far apart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e62e26-18ce-4225-983a-cfa1ff39f235",
   "metadata": {},
   "source": [
    "#### Divisive Clustering\n",
    "    dataset: {x1, x2, ..., xn}\n",
    "    start with all data in one cluster\n",
    "    repeat:\n",
    "        choose one cluster G\n",
    "        remove the point in G with largest average dissimilarity with all other points in G\n",
    "        add the point to a new cluster in H\n",
    "        repeat until no point in G is closer to H on average\n",
    "    until all clusters are singletons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea9473-6b18-45c3-9496-9b45687531da",
   "metadata": {},
   "source": [
    "#### Compactness\n",
    "    K-Mean\n",
    "    Gaussian Mixture Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02f9f4-27c1-404c-b65b-d4452366c5db",
   "metadata": {},
   "source": [
    "#### Connectivity\n",
    "    spectral clustering\n",
    "        eigenvectors of the laplacian matrix provide an embedding of the data based on similarity\n",
    "        if clusters are loosely connected:\n",
    "            1st laplacian e-vector is all 1s\n",
    "            for two clusters: second e-vector finds balanced cut\n",
    "            for k clusters, the e-vectors are slightly perturbed\n",
    "\n",
    "        algorithm:\n",
    "            input: similarity matrix W, number of clusters k\n",
    "            build similarity graphs: G(V, E, W)\n",
    "            compute first k evectors {v1, v2, ..., vk} of the laplacian matrix\n",
    "            build the matrix veigen in Rnxk w/ evectors as columns\n",
    "            interpret the rows of veigen as new data points zi in Rk\n",
    "\n",
    "    Gaussian mixture model\n",
    "        non-deterministic\n",
    "        \n",
    "        \n",
    "    graph clustering\n",
    "        input: {x1, x2, ..., xn}\n",
    "        similarity weight matrix: W = {wij} w/ i, j \n",
    "\n",
    "    similarity graph construction\n",
    "        similarity graph: G(V, E, W)\n",
    "            model local neighborhood relations between data samples\n",
    "\n",
    "        similarity functions:\n",
    "            e-nearest neightbors:\n",
    "                wij = {1 if ||xi - xj|| â‰¤ e else 0}\n",
    "\n",
    "            mutual k-nearest neighbors:\n",
    "                wij = 1 if xi and xj are k-nearest neighbors of each other\n",
    "\n",
    "    Graph Notation:\n",
    "        adjacency matrix: W = (wij)\n",
    "\n",
    "        degree of a vertex: di = sum_j(wij)\n",
    "\n",
    "        degree matrix: D = diag(d1, d2, ..., dn)\n",
    "\n",
    "        un-normalized graph laplacian: L = D - W\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33cfddc-6e89-4d56-80c0-cf4a293546a9",
   "metadata": {},
   "source": [
    "#### Cluster Analysis\n",
    "    Partitioning Criteria\n",
    "        single level vs hierarchical (multi-level is often desirable)\n",
    "        \n",
    "    Separation of Clusters\n",
    "        exclusive (each point belongs to one cluster)\n",
    "        \n",
    "        non-exclusive (each point can belong to more than one class)\n",
    "        \n",
    "    Distance Dalculation\n",
    "        euclidean or other?\n",
    "\n",
    "    Clustering Quality\n",
    "        a good method --> high quality clusters\n",
    "        \n",
    "        measuring:\n",
    "            external\n",
    "                require ground truth labels\n",
    "                examples: adjusted rand index, fowlkes-mallows scores, homogeneity, completeness\n",
    "            internal\n",
    "\n",
    "    External:\n",
    "        supervised Rand index\n",
    "            a dataset S = {x1, x2, ..., xn}\n",
    "            ground truth clusters X = {X1, X2, ..., XT}\n",
    "            clustering results C = {C1, C2, ..., CK}\n",
    "\n",
    "            count # of pairs of samples in the same subset of X and in the same subset of C: a (aka TP)\n",
    "            count # of pairs of samples in different subsets of X and in different subsets of C: b (aka TN)\n",
    "            count # of pairs in same subset of X and in different subsets of C: c (aka FN)\n",
    "            count # of pairs in different subsets of X and in same subset of C: d (aka FP)\n",
    "\n",
    "        unsupervised silhouette coefficient\n",
    "            a dataset S = {x1, x2, ..., xn}\n",
    "            clustering results C = {C1, C2, ..., CK}\n",
    "            for each sample xi in Cm\n",
    "                calculate mean distance between xi and all other samples in Cm (ai)\n",
    "                calculate smallest mean distance between xi and samples in other clusters (bi)\n",
    "                calculate silhouette of xi ((bi - ai) / max(bi, ai))\n",
    "                calculate silhouette coefficient of clustering result\n",
    "                    max average silhouette over all clusters\n",
    "\n",
    "    Determine Number of Clusters:\n",
    "        empirical:\n",
    "            num_clusters = k = sqrt(n/2) where n is num_data_points\n",
    "\n",
    "        elbow method:\n",
    "            within-cluster variance is a measure of compactness\n",
    "            lower value of with-cluster variance --> higher compactness\n",
    "            use the turning point in the curve of sum of within-cluster variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1f106-d9a2-4866-82de-9e645bf2b594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bd4ad-6993-494a-ba24-385ca0d20968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
