{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f197e08-4b30-4d99-9e06-09150552e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50c34589-2ead-4c2e-b528-e8583cc98e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2996.915283203125\n",
      "199 1986.640380859375\n",
      "299 1318.0299072265625\n",
      "399 875.5083618164062\n",
      "499 582.6061401367188\n",
      "599 388.72296142578125\n",
      "699 260.37506103515625\n",
      "799 175.404052734375\n",
      "899 119.1455078125\n",
      "999 81.89423370361328\n",
      "1099 57.22587203979492\n",
      "1199 40.88872528076172\n",
      "1299 30.067890167236328\n",
      "1399 22.899829864501953\n",
      "1499 18.151002883911133\n",
      "1599 15.004512786865234\n",
      "1699 12.919422149658203\n",
      "1799 11.537494659423828\n",
      "1899 10.62143611907959\n",
      "1999 10.014086723327637\n",
      "Results: y = 0.008110667578876019 + 0.8239452838897705 x + -0.00139922508969903 x^2 + -0.08866550773382187 x^3\n"
     ]
    }
   ],
   "source": [
    "dtype = tc.float\n",
    "device = tc.device(\"cpu\")\n",
    "\n",
    "x = tc.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = tc.sin(x)\n",
    "\n",
    "a = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "b = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "c = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "d = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(2000):\n",
    "    y_pred = a + b*x + c*x**2 + d*x**3\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f\"Results: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "571e0f1a-5b3b-41f4-bd85-b22eeecae131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 374.52178955078125\n",
      "199 252.982666015625\n",
      "299 171.93011474609375\n",
      "399 117.84918975830078\n",
      "499 81.7451400756836\n",
      "599 57.62850570678711\n",
      "699 41.5095100402832\n",
      "799 30.729320526123047\n",
      "899 23.514833450317383\n",
      "999 18.68340492248535\n",
      "1099 15.445511817932129\n",
      "1199 13.27396011352539\n",
      "1299 11.816438674926758\n",
      "1399 10.837404251098633\n",
      "1499 10.17919635772705\n",
      "1599 9.73630142211914\n",
      "1699 9.438043594360352\n",
      "1799 9.236984252929688\n",
      "1899 9.101323127746582\n",
      "1999 9.009705543518066\n"
     ]
    }
   ],
   "source": [
    "x = tc.linspace(-math.pi, math.pi, 2000)\n",
    "y = tc.sin(x)\n",
    "\n",
    "p = tc.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    tc.nn.Linear(3, 1),\n",
    "    tc.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "loss_fn = tc.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    y_pred = model(xx)\n",
    "\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "    model.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "\n",
    "linear_layer = model[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a17b002-aa1e-4786-af94-b98ca3405195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 771.5487060546875\n",
      "199 586.7696533203125\n",
      "299 445.9894714355469\n",
      "399 332.6747741699219\n",
      "499 240.30636596679688\n",
      "599 165.83172607421875\n",
      "699 107.88685607910156\n",
      "799 65.2943115234375\n",
      "899 36.54120635986328\n",
      "999 19.61551856994629\n",
      "1099 11.726996421813965\n",
      "1199 9.287557601928711\n",
      "1299 8.935791015625\n",
      "1399 8.90194320678711\n",
      "1499 8.905007362365723\n",
      "1599 8.907093048095703\n",
      "1699 8.907391548156738\n",
      "1799 8.927767753601074\n",
      "1899 8.907142639160156\n",
      "1999 8.907236099243164\n"
     ]
    }
   ],
   "source": [
    "x = tc.linspace(-math.pi, math.pi, 2000)\n",
    "y = tc.sin(x)\n",
    "\n",
    "p = tc.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    tc.nn.Linear(3, 1),\n",
    "    tc.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "loss_fn = tc.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "for t in range(2000):\n",
    "    y_pred = model(xx)\n",
    "\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "    model.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3908c4a-bf9e-4842-96be-a021e8032432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 32.56114959716797\n",
      "99 1.6436736583709717\n",
      "149 0.14426842331886292\n",
      "199 0.019672388210892677\n",
      "249 0.003468212205916643\n",
      "299 0.0007053564768284559\n",
      "349 0.00015541346510872245\n",
      "399 3.5889854189008474e-05\n",
      "449 8.535595952707808e-06\n",
      "499 2.0695404145953944e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m            Net\n",
       "\u001b[0;31mString form:\u001b[0m    \n",
       "Net(\n",
       "  (ln1): Linear(in_features=1000, out_features=100, bias=True)\n",
       "  (ln2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")\n",
       "\u001b[0;31mDocstring:\u001b[0m       <no docstring>\n",
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool\n",
       "\u001b[0;31mInit docstring:\u001b[0m  Initialize internal Module state, shared by both nn.Module and ScriptModule."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.ln1 = tc.nn.Linear(d_in, d_hidden)\n",
    "        self.ln2 = tc.nn.Linear(d_hidden, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_relu = self.ln1(x).clamp(min=0)\n",
    "        y_pred = self.ln2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "train_size, d_in, d_hidden, d_out = 64, 1000, 100, 10\n",
    "x = torch.randn(train_size, d_in)\n",
    "y = torch.randn(train_size, d_out)\n",
    "\n",
    "model = Net(d_in, d_hidden, d_out)\n",
    "\n",
    "optimizer = tc.optim.SGD(model.parameters(), lr=1e-4)\n",
    "loss_fn = tc.nn.MSELoss(reduction='sum')\n",
    "\n",
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    if t % 50 == 49:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6097c-a369-4fb7-8159-1b147554a755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
