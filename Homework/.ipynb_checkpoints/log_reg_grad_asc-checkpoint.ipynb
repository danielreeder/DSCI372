{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e00769ed-deda-4788-867a-cacdaf349c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "cc0f68f1-8d67-4bf9-b7bc-17b524efd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR Q1\n",
    "\n",
    "def compute_gradient(X, y, w):\n",
    "    err = y - X.dot(w)\n",
    "    grad = -2 * err\n",
    "    grad = np.mean(np.multiply(grad, X), axis=0)\n",
    "    return grad.reshape(-1, 1)\n",
    "\n",
    "def gradient_descent(X, y, w, num_iterations, alpha):\n",
    "    for i in np.arange(num_iterations):\n",
    "        gradient = compute_gradient(X, y, w)\n",
    "        w = w - (alpha * gradient)\n",
    "        loss = np.mean((X.dot(w) - y) ** 2)\n",
    "        print(f\"Iteration {i}:\\nWeights: w0={w[0]}\\tw1={w[1]}\\tw2={w[2]}\\nLoss: {loss}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "e474591d-716e-43d7-8864-e215d1f5b2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FUNCTION FOR Q2\n",
    "\n",
    "def check_predictions(X, y, w):\n",
    "    preds = np.array(X.dot(w))\n",
    "    i = 0\n",
    "    for pred in preds:\n",
    "        if pred > 0:\n",
    "            preds[i] = 1\n",
    "        else:\n",
    "            preds[i] = -1\n",
    "        i += 1\n",
    "    return preds == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "ac5300f1-079c-4161-b04c-aa4d9ff588d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR Q3\n",
    "\n",
    "def map_to_binary(y):\n",
    "    map = np.zeros(len(y), dtype=int)\n",
    "    map[y==1] = 1\n",
    "    return map\n",
    "        \n",
    "def get_gradients(X, w, y):\n",
    "    n = len(y)\n",
    "    grads = np.zeros(2)\n",
    "    mapped_y = map_to_binary(y)\n",
    "    \n",
    "    for i in np.arange(2):\n",
    "        for j in np.arange(n):\n",
    "            k = mapped_y[j]\n",
    "            grads[i] += (k * d_dw_positive(X[j], w, i)) + ((1-k) * d_dw_negative(X[j], w, i))\n",
    "        grads[i] = np.mean(grads[i])\n",
    "    return grads\n",
    "\n",
    "def d_dw_positive(x, w, i):\n",
    "    return (x[i]) / (1 + np.exp(w.dot(x)))\n",
    "                       \n",
    "def d_dw_negative(x, w, i):\n",
    "    return -(x[i] * np.exp(w.dot(x))) / (1 + np.exp(w.dot(x)))\n",
    "\n",
    "def prob_positive(x, w):\n",
    "    return 1 / (1 + np.exp(w.dot(x)))\n",
    "    \n",
    "def prob_negative(x, w):\n",
    "    return 1 - prob_positive(x, w)\n",
    "\n",
    "def log_likelihood(X, w, y):\n",
    "    n = len(y)\n",
    "    agg = 0\n",
    "    \n",
    "    for i in np.arange(n):\n",
    "        if y[i] == 1:\n",
    "            agg += np.log(prob_positive(X[i], w))\n",
    "        elif y[i] == -1:\n",
    "            agg += np.log(prob_negative(X[i], w))\n",
    "    return agg / n\n",
    "\n",
    "def gradient_ascent(X, w, y, num_iterations, alpha):\n",
    "    for i in np.arange(num_iterations):\n",
    "        grads = get_gradients(X, w, y)\n",
    "        w = w + (alpha * grads)\n",
    "        logL = -log_likelihood(X, w, y)\n",
    "        print(f\"Iteration {i}:\\nWeights: w1={w[0]}\\tw2={w[1]}\\nLog Likelihood: {logL}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "44e2dc72-5c8b-44d6-a93a-d81dcc45ea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0:\n",
      "Weights: w0=[-0.19]\tw1=[-0.36333333]\tw2=[0.13333333]\n",
      "Loss: 5.261425925925926\n",
      "\n",
      "Iteration 1:\n",
      "Weights: w0=[-0.32788889]\tw1=[-0.64577778]\tw2=[0.23944444]\n",
      "Loss: 3.31300890946502\n",
      "\n",
      "Iteration 2:\n",
      "Weights: w0=[-0.42608519]\tw1=[-0.86607778]\tw2=[0.32455556]\n",
      "Loss: 2.1533203291495204\n",
      "\n",
      "Iteration 3:\n",
      "Weights: w0=[-0.49410111]\tw1=[-1.0386084]\tw2=[0.39344136]\n",
      "Loss: 1.458176228541203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1.\n",
    "\n",
    "# (a)\n",
    "\n",
    "df_least_square = pd.DataFrame({\"x1\": [1, -1, 2], \n",
    "                                \"x2\": [1, -2, -1], \n",
    "                                \"y\": [-0.8, 0.1, -5.0]\n",
    "                               })\n",
    "\n",
    "w = np.array([0, 0, 0]).reshape(-1, 1)\n",
    "num_iterations = 4\n",
    "alpha = 0.05\n",
    "\n",
    "X = df_least_square.iloc[:, 0:-1].values\n",
    "y = df_least_square.iloc[:, [-1]].values\n",
    "\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "gradient_descent(X, y, w, num_iterations, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "c88b61d2-731f-4a23-b4e8-c41bcdb0d190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 1\n",
      "Weights: [1 1]\n",
      "\n",
      "i: 2\n",
      "Weights: [-1  2]\n",
      "\n",
      "i: 3\n",
      "Weights: [-1  2]\n",
      "\n",
      "i: 4\n",
      "Weights: [-1  2]\n",
      "\n",
      "after_train_preds = y: [ True  True  True  True]\n",
      "After training, the perceptron correctly predicts each value of y.\n"
     ]
    }
   ],
   "source": [
    "# Q2\n",
    "\n",
    "# (a)\n",
    "\n",
    "df_perceptron = pd.DataFrame({\"x1\": [1, 2, -3, -3],\n",
    "                              \"x2\": [1, -1, -1, 1],\n",
    "                              \"y\": [1, -1, 1, 1]\n",
    "                             })\n",
    "\n",
    "w = np.array([0, 0])\n",
    "\n",
    "X = df_perceptron.iloc[:, 0:-1].values\n",
    "y = df_perceptron.iloc[:, -1].values\n",
    "\n",
    "i = 1\n",
    "for xi, yi in zip(X, y):\n",
    "    pred = w.dot(xi)\n",
    "    if pred > 0:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "\n",
    "    if pred != yi:\n",
    "        update = yi * xi\n",
    "        w += update\n",
    "    print(f\"i: {i}\\nWeights: {w}\\n\")\n",
    "    i += 1\n",
    "        \n",
    "after_train_preds = check_predictions(X, y, w)\n",
    "print(f\"after_train_preds = y: {after_train_preds}\")\n",
    "print(\"After training, the perceptron correctly predicts each value of y.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "c06ed1c2-78a2-4183-99a5-37bf0f4d1fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 2\n",
      "Weights: [-2  1]\n",
      "\n",
      "i: 1\n",
      "Weights: [-1  2]\n",
      "\n",
      "i: 3\n",
      "Weights: [-1  2]\n",
      "\n",
      "i: 4\n",
      "Weights: [-1  2]\n",
      "\n",
      "after_train_preds = y: [ True  True  True  True]\n",
      "After training, the perceptron correctly predicts each value of y.\n"
     ]
    }
   ],
   "source": [
    "# (b)\n",
    "\n",
    "w = np.array([0, 0])\n",
    "X = df_perceptron.iloc[:, 0:-1].values\n",
    "y = df_perceptron.iloc[:, -1].values\n",
    "\n",
    "for i in np.array([2, 1, 3, 4])-1:\n",
    "    pred = w.dot(X[i])\n",
    "    if pred > 0:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "\n",
    "    if pred != y[i]:\n",
    "        update = y[i] * X[i]\n",
    "        w += update\n",
    "    print(f\"i: {i+1}\\nWeights: {w}\\n\")\n",
    "after_train_preds = check_predictions(X, y, w)\n",
    "print(f\"after_train_preds = y: {after_train_preds}\")\n",
    "print(\"After training, the perceptron correctly predicts each value of y.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "7486defc-dc85-4daf-89f7-418a013bdff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning Rate: 0.01\n",
      "\n",
      "\n",
      "Iteration 0:\n",
      "Weights: w1=-0.035\tw2=0.01\n",
      "Log Likelihood: 0.7271866369644129\n",
      "\n",
      "Iteration 1:\n",
      "Weights: w1=-0.06796420111955323\tw2=0.0198127413151905\n",
      "Log Likelihood: 0.7610167577344238\n",
      "\n",
      "Iteration 2:\n",
      "Weights: w1=-0.09901916858835423\tw2=0.029446490820756004\n",
      "Log Likelihood: 0.7944635499108479\n",
      "\n",
      "Iteration 3:\n",
      "Weights: w1=-0.12829031804928573\tw2=0.038910058394302276\n",
      "Log Likelihood: 0.8273894804879601\n",
      "\n",
      "Iteration 4:\n",
      "Weights: w1=-0.15589945711813977\tw2=0.04821246336183652\n",
      "Log Likelihood: 0.8596892535728781\n",
      "\n",
      "Iteration 5:\n",
      "Weights: w1=-0.1819630963645329\tw2=0.05736268049013239\n",
      "Log Likelihood: 0.8912852359512726\n",
      "\n",
      "Iteration 6:\n",
      "Weights: w1=-0.20659138830688095\tw2=0.06636945614480744\n",
      "Log Likelihood: 0.9221229610402126\n",
      "\n",
      "Iteration 7:\n",
      "Weights: w1=-0.2298875543545352\tw2=0.0752411827620478\n",
      "Log Likelihood: 0.9521669702366171\n",
      "\n",
      "Iteration 8:\n",
      "Weights: w1=-0.2519476745617072\tw2=0.0839858195845941\n",
      "Log Likelihood: 0.9813971230619607\n",
      "\n",
      "Iteration 9:\n",
      "Weights: w1=-0.2728607356978055\tw2=0.09261084869570683\n",
      "Log Likelihood: 1.0098054204638662\n",
      "\n",
      "Iteration 10:\n",
      "Weights: w1=-0.2927088545581437\tw2=0.10112325703921261\n",
      "Log Likelihood: 1.0373933313247496\n",
      "\n",
      "Iteration 11:\n",
      "Weights: w1=-0.31156761298016133\tw2=0.10952953689363296\n",
      "Log Likelihood: 1.0641695818742107\n",
      "\n",
      "Iteration 12:\n",
      "Weights: w1=-0.329506457558155\tw2=0.11783569892850673\n",
      "Log Likelihood: 1.0901483535878551\n",
      "\n",
      "Iteration 13:\n",
      "Weights: w1=-0.34658913033597405\tw2=0.12604729340033402\n",
      "Log Likelihood: 1.1153478312868426\n",
      "\n",
      "Iteration 14:\n",
      "Weights: w1=-0.36287410704776873\tw2=0.1341694362139301\n",
      "Log Likelihood: 1.1397890452440649\n",
      "\n",
      "Iteration 15:\n",
      "Weights: w1=-0.37841502721744213\tw2=0.14220683749551838\n",
      "Log Likelihood: 1.1634949562821166\n",
      "\n",
      "Iteration 16:\n",
      "Weights: w1=-0.39326110610792836\tw2=0.15016383102922443\n",
      "Log Likelihood: 1.186489739299943\n",
      "\n",
      "Iteration 17:\n",
      "Weights: w1=-0.40745752258720097\tw2=0.15804440343705764\n",
      "Log Likelihood: 1.2087982273128137\n",
      "\n",
      "Iteration 18:\n",
      "Weights: w1=-0.4210457798372749\tw2=0.16585222237077052\n",
      "Log Likelihood: 1.2304454843466135\n",
      "\n",
      "Iteration 19:\n",
      "Weights: w1=-0.4340640377894331\tw2=0.1735906632642561\n",
      "Log Likelihood: 1.2514564811132125\n",
      "\n",
      "\n",
      "Learning Rate: 0.2\n",
      "\n",
      "\n",
      "Iteration 0:\n",
      "Weights: w1=-0.7000000000000001\tw2=0.2\n",
      "Log Likelihood: 1.6732274869873422\n",
      "\n",
      "Iteration 1:\n",
      "Weights: w1=-0.7754396409327717\tw2=0.3502910865439577\n",
      "Log Likelihood: 1.848097531511751\n",
      "\n",
      "Iteration 2:\n",
      "Weights: w1=-0.8181535371314034\tw2=0.4857541844684759\n",
      "Log Likelihood: 1.9667573260064277\n",
      "\n",
      "Iteration 3:\n",
      "Weights: w1=-0.848110682489349\tw2=0.6091516239542787\n",
      "Log Likelihood: 2.0616444881945073\n",
      "\n",
      "Iteration 4:\n",
      "Weights: w1=-0.8727703548428949\tw2=0.7221340231964792\n",
      "Log Likelihood: 2.145257930085205\n",
      "\n",
      "Iteration 5:\n",
      "Weights: w1=-0.8953657198814481\tw2=0.8260162856782156\n",
      "Log Likelihood: 2.2231450973975098\n",
      "\n",
      "Iteration 6:\n",
      "Weights: w1=-0.9173248523206311\tw2=0.9219512105980494\n",
      "Log Likelihood: 2.2978546255920533\n",
      "\n",
      "Iteration 7:\n",
      "Weights: w1=-0.9392326080264521\tw2=1.0109655047740063\n",
      "Log Likelihood: 2.370532737348458\n",
      "\n",
      "Iteration 8:\n",
      "Weights: w1=-0.9612749182748388\tw2=1.0939646252629196\n",
      "Log Likelihood: 2.4416603792544858\n",
      "\n",
      "Iteration 9:\n",
      "Weights: w1=-0.9834573959008288\tw2=1.171735501418133\n",
      "Log Likelihood: 2.511412507573178\n",
      "\n",
      "Iteration 10:\n",
      "Weights: w1=-1.0057138923503455\tw2=1.2449535065216124\n",
      "Log Likelihood: 2.5798343745867207\n",
      "\n",
      "Iteration 11:\n",
      "Weights: w1=-1.0279588388667216\tw2=1.3141932033870893\n",
      "Log Likelihood: 2.646925760955868\n",
      "\n",
      "Iteration 12:\n",
      "Weights: w1=-1.0501107161027587\tw2=1.3799409271367569\n",
      "Log Likelihood: 2.71267880756806\n",
      "\n",
      "Iteration 13:\n",
      "Weights: w1=-1.072101015094024\tw2=1.442607534516343\n",
      "Log Likelihood: 2.777092967339005\n",
      "\n",
      "Iteration 14:\n",
      "Weights: w1=-1.0938762435255318\tw2=1.5025402786293214\n",
      "Log Likelihood: 2.840179175347239\n",
      "\n",
      "Iteration 15:\n",
      "Weights: w1=-1.1153968788765702\tw2=1.560033309157943\n",
      "Log Likelihood: 2.9019593443802014\n",
      "\n",
      "Iteration 16:\n",
      "Weights: w1=-1.136635216275864\tw2=1.6153366568730165\n",
      "Log Likelihood: 2.962464164862294\n",
      "\n",
      "Iteration 17:\n",
      "Weights: w1=-1.157573030735422\tw2=1.6686637629982148\n",
      "Log Likelihood: 3.0217305820020175\n",
      "\n",
      "Iteration 18:\n",
      "Weights: w1=-1.1781994464342491\tw2=1.7201977089168672\n",
      "Log Likelihood: 3.079799520146844\n",
      "\n",
      "Iteration 19:\n",
      "Weights: w1=-1.1985091459133794\tw2=1.7700963329423498\n",
      "Log Likelihood: 3.1367140390440977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3\n",
    "\n",
    "# (b)\n",
    "\n",
    "df_logistic_reg = pd.DataFrame({\"x1\": [1, 2, -3, -3],\n",
    "                                \"x2\": [1, -1, -1, 1],\n",
    "                                \"y\": [1, -1, 1, 1]\n",
    "                               })\n",
    "\n",
    "X = df_logistic_reg.iloc[:, 0:-1].values\n",
    "w = np.array([0, 0])\n",
    "y = df_logistic_reg.iloc[:, -1].values\n",
    "num_iterations = 20\n",
    "alphas = np.array([0.01, 0.2])\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(f\"\\nLearning Rate: {alpha}\\n\\n\")\n",
    "    gradient_ascent(X, w, y, num_iterations, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd4b3a-d290-47ef-b16b-7d94f64af423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22762126-0e47-41a3-b3d3-64cc1419edc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
